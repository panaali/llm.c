# Integrating LoRA with LLM.C

## LoRA is just two weight matrices multipying at the same time. The goal is to parallelize LoRA so that fine-tuning uses less peak GPU memory.

